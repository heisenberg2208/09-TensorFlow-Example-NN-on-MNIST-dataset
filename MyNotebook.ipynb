{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devendra/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-cf8086cdf0d8>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/devendra/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/devendra/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/devendra/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/devendra/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/devendra/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n",
      "(128, 10)\n",
      "(128, 784)\n",
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(2):\n",
    "        batch_x , batch_y = mnist.train.next_batch(128)\n",
    "        print(batch_x.shape)\n",
    "        print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - create placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x , n_y):\n",
    "    X = tf.placeholder(tf.float32 , (n_x,None))\n",
    "    Y = tf.placeholder(tf.float32 , (n_y,None))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"Placeholder:0\", shape=(784, ?), dtype=float32)\n",
      "y = Tensor(\"Placeholder_1:0\", shape=(10, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X,Y = create_placeholders(784,10)\n",
    "print(\"x = \"+str(X))\n",
    "print(\"y = \"+str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    xavier_initializer = tf.contrib.layers.xavier_initializer(seed=1)\n",
    "    zeros_initializer = tf.zeros_initializer()\n",
    "    W1 = tf.get_variable(\"W1\",[256,784],initializer=xavier_initializer)\n",
    "    b1 = tf.get_variable(\"b1\",[256,1],initializer=zeros_initializer)\n",
    "    \n",
    "    W2 = tf.get_variable(\"W2\",[256,256],initializer=xavier_initializer)\n",
    "    b2 = tf.get_variable(\"b2\",[256,1],initializer=zeros_initializer)\n",
    "    \n",
    "    W3 = tf.get_variable(\"W3\",[10,256],initializer=xavier_initializer)\n",
    "    b3 = tf.get_variable(\"b3\",[10,1],initializer=zeros_initializer)\n",
    "    \n",
    "    parameters = {\n",
    "        \"W1\":W1,\n",
    "        \"b1\":b1,\n",
    "        \"W2\":W2,\n",
    "        \"b2\":b2,\n",
    "        \"W3\":W3,\n",
    "        \"b3\":b3\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(256, 784) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(256, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(256, 256) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(256, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(10, 256) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(10, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \"+str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \"+str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \"+str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \"+str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \"+str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \"+str(parameters[\"b3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Forward propagation in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "    Z2 = tf.add(tf.matmul(W2,Z1),b2)\n",
    "    Z3 = tf.add(tf.matmul(W3,Z2),b3)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(10, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X , Y = create_placeholders(784,10)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  - Compute cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-6e56da6a9aa0>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,Y = create_placeholders(784,10)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    print(\"cost = \"+str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, for gradient descent the optimizer would be:\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "```\n",
    "\n",
    "To make the optimization you would do:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(learning_rate=0.1,num_epochs=500,minibatch_size=128,print_cost=True):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    n_x = 784\n",
    "    n_y = 10\n",
    "    \n",
    "    X,Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(Z3) , tf.argmax(Y))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\"))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    train_X = mnist.train.images.T\n",
    "    train_Y = mnist.train.labels.T\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            seed = seed + 1\n",
    "            batch_X, batch_Y = mnist.train.next_batch(minibatch_size)\n",
    "            minibatch_X = batch_X.T\n",
    "            minibatch_Y = batch_Y.T\n",
    "            _,minibatch_cost = sess.run([optimizer,cost],feed_dict={X:minibatch_X , Y:minibatch_Y})\n",
    "            \n",
    "            \n",
    "            \n",
    "            if print_cost and epoch%100 == 0:\n",
    "                print(\"cost after epoch %i:%f\"%(epoch,minibatch_cost))\n",
    "                acc = sess.run(accuracy, feed_dict={X: train_X,Y: train_Y})\n",
    "                print(\"Accuracy after epoch %i:%f percentage\\n\"%(epoch,acc*100))\n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict={X: train_X,Y: train_Y})\n",
    "        print(\"Accuracy on train images %f\\n\"%(acc*100))\n",
    "        acc = sess.run(accuracy, feed_dict={X: mnist.test.images.T,Y: mnist.test.labels.T})\n",
    "        print(\"Accuracy on test images %f\\n\"%(acc*100))\n",
    "        parameters = sess.run(parameters)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after epoch 0:2.456936\n",
      "Accuracy after epoch 0:11.749091 percentage\n",
      "\n",
      "cost after epoch 100:32.844685\n",
      "Accuracy after epoch 100:83.672726 percentage\n",
      "\n",
      "cost after epoch 200:9.914660\n",
      "Accuracy after epoch 200:86.421818 percentage\n",
      "\n",
      "cost after epoch 300:7.101398\n",
      "Accuracy after epoch 300:85.141820 percentage\n",
      "\n",
      "cost after epoch 400:2.654395\n",
      "Accuracy after epoch 400:87.094545 percentage\n",
      "\n",
      "Accuracy on train images 88.107270\n",
      "\n",
      "Accuracy on test images 88.370001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
